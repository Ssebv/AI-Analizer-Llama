# ğŸ“° AIâ€‘Analizer

Sistema de anÃ¡lisis inteligente de noticias construido con **LangChain + LangGraph**, agentes especializados y una interfaz **Streamlit**.

![python interactive](img/Interactive.png)

Con agentes especializados la IA convierte las noticias entregadas en insights claros, en tiempo real y sin trabajo manual - esto puede ser llevado a documentos tecnicos, soluciones o depende de area que se quiera integrar. Cada agente resuelve un paso (buscar, analizar, comparar segun lo programado) y el grafo los coordina, asÃ­ el sistema escala y se amplÃ­a fÃ¡cil. El proyecto demostrÃ³ esto: indexÃ³ una vez los datos, respondiÃ³ consultas complejas al instante y entregÃ³ informaciÃ³n lista para decidir, mostrando el valor directo de adoptar esta arquitectura en la empresa.

Capturas en IMG y en el CSV una prueba en entorno local.

---

## Tabla de contenido

1. [CaracterÃ­sticas principales](#caracterÃ­sticas-principales)
2. [Arquitectura](#arquitectura)
3. [Requisitos](#requisitos)
4. [InstalaciÃ³n](#instalaciÃ³n)

   * [Usando Pipenv](#usando-pipenv)
   * [Usando `requirements.txt`](#usando-requirementstxt)
5. [EjecuciÃ³n](#ejecuciÃ³n)

   * [Verificador de entorno](#verificador-de-entorno)
   * [AplicaciÃ³n Streamlit](#aplicaciÃ³n-streamlit)
   * [CLI interactiva](#cli-interactiva)
   * [Informe batch automÃ¡tico](#informe-batch-automÃ¡tico)
6. [Estructura del proyecto](#estructura-del-proyecto)
7. [Variables de entorno](#variables-de-entorno)
8. [Comandos Ãºtiles](#comandos-Ãºtiles)
9. [ContribuciÃ³n](#contribuciÃ³n)

---

## CaracterÃ­sticas principales

* **ETL de noticias** en Excel (`NewsDataProcessor`).
* **Vectorâ€‘store ChromaDB** con embeddings de *Sentenceâ€‘Transformers*.
* **RAG** con LlamaÂ 3 vÃ­a **Ollama**.
* **Agentes base** (text, analysis, conversational) + **agentes especializados** (clustering, temporal, comparativoâ€¦).
* **LangGraph** para orquestar flujos complejos.
* **Verificador de sistema** (`SystemChecker`) â€“Â Chequea Python, dependencias, Ollama, estructura.
* **Streamlit app** con dashboard, chat, anÃ¡lisis automÃ¡tico y exportaciÃ³n (CSV/Excel).
* **CLI interactiva** (`python main.py interactive`) para pruebas rÃ¡pidas.
* **Modo lote**: genera un JSON con respuestas a preguntas predefinidas.

## Arquitectura

```text
Excel â†’ DataProcessor â†’ ChromaDB (VectorStore) â†â†’ RAG (LangChain)
                                       â†‘
                Agents (Base & Specialized) â† LangGraph workflow
                                       â†‘
                                 Streamlit UI / CLI
```

> **Nota:** El mÃ³dulo `src/utils/system_checker.py` se ejecuta antes de inicializar todo para garantizar que el entorno estÃ© listo.

## Requisitos

* **Python â‰¥ 3.11**
* **Ollama** corriendo localmente (`ollama serve`).
* Modelo **LlamaÂ 3** indicado en tu `.env` (p.Â ej. `llama3:8b`) **descargado previamente**:

  ```bash
  ollama pull llama3:8b   # o el que indiques en LLAMA_MODEL
  ```
* Paquetes del proyecto instalados con **Pipenv** o **requirements.txt**.
* (Opcional) **Homebrew** si usas macOS para facilitar la instalaciÃ³n de Python y Ollama.

> â±ï¸ **Rendimiento**: el tiempo de inicializaciÃ³n (creaciÃ³n del vectorâ€‘store y consultas) depende directamente de la velocidad de tu CPU/GPU y disco. Las pruebas se realizaron en un **MacBookÂ Pro M1** con 16â€¯GBÂ RAM utilizando Homebrew como gestor de paquetes.

---

## InstalaciÃ³n

### Usando Pipenv

```bash
# 1. Clona el repo
$ git clone https://github.com/tuâ€‘usuario/aiâ€‘analizer.git
$ cd aiâ€‘analizer

# 2. Instala dependencias + crea venv
$ pipenv install --python 3.11

# 3. Activa el entorno
$ pipenv shell
```

### Usando `requirements.txt`

```bash
# Crea y activa un venv (opcional)
$ python -m venv .venv && source .venv/bin/activate

# Instala dependencias
$ pip install -r requirements.txt
```

## EjecuciÃ³n

### Verificador de entorno

Ejecuta **antes** de todo para detectar problemas:

```bash
$ python main.py verify        # o python verify.py
```

### AplicaciÃ³n Streamlit

```bash
$ streamlit run app.py
```

*Sube tu Excel â†’ â€œProcesar Datasetâ€ â†’ â€œCrear Vector Storeâ€ y comienza a explorar.*

### CLI interactiva

```bash
$ python main.py interactive
```

Comandos disponibles dentro del prompt:

```
agentes   # lista agentes
auto      # modo automÃ¡tico
usar analysis    # fuerza un agente
estado    # muestra health snapshot
limpiar   # borra historial
salir     # termina
```

### Informe batch automÃ¡tico

Por defecto responde a 5 preguntas y guarda un JSON:

```bash
$ python main.py
```

Preguntas personalizadas (separadas por `||`):

```bash
$ REPORT_QUESTIONS="Â¿QuÃ© dice la prensa sobre IA?||Compara sentimiento en economÃ­a" python main.py
```

## Estructura del proyecto

```text
ai-analizer/
â”œâ”€â”€ app.py                # Frontâ€‘end Streamlit (dashboard + chat)
â”œâ”€â”€ main.py               # Entrypoint CLI + batch + integraciÃ³n completa
â”œâ”€â”€ verify.py             # Verificador de entorno (opcional)
â”œâ”€â”€ README.md             # Este documento
â”œâ”€â”€ .env                  # ConfiguraciÃ³n local
â”œâ”€â”€ requirements.txt      # Dependencias (pip) / Pipfile para Pipenv
â”œâ”€â”€ chroma_db/            # Persistencia del vectorâ€‘store (se autogenera)
â””â”€â”€ src/
    â”œâ”€â”€ core/
    â”‚   â”œâ”€â”€ system.py     # `IntegratedNewsSystem` â€“Â motor reutilizable
    â”‚   â””â”€â”€ uploads/      # Excel subido vÃ­a Streamlit (copia)
    â”œâ”€â”€ agents/
    â”‚   â”œâ”€â”€ llama_agents.py        # Agentes base (text, analysis, conversational)
    â”‚   â”œâ”€â”€ specialized_agents.py  # FÃ¡brica y healthâ€‘check de agentes temÃ¡ticos
    â”‚   â””â”€â”€ new_agents_graph.py    # Grafo LangGraph con agentes de noticias
    â”œâ”€â”€ data/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ data_processor.py      # ETL y limpieza de Excel
    â”‚   â”œâ”€â”€ vectorstore_manager.py # Crea / carga ChromaDB, estadÃ­sticas
    â”‚   â””â”€â”€ noticias_test_ingeniero_IA.xlsx  # Dataset de ejemplo
    â”œâ”€â”€ graph/
    â”‚   â””â”€â”€ ...                    # (espacio para futuros flujos LangGraph)
    â”œâ”€â”€ models/
    â”‚   â”œâ”€â”€ embeddings.py          # Plantilla para embeddings locales
    â”‚   â””â”€â”€ llama_setup.py         # Script para configurar modelo en Ollama
    â””â”€â”€ utils/
        â””â”€â”€ system_checker.py      # Clase `SystemChecker` usada por verify.py
```

### Desglose rÃ¡pido de cada mÃ³dulo

| Archivo / carpeta                     | Rol principal                                                                                                                        |
| ------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------ |
| **app.py**                            | Interfaz Streamlit: carga Excel, crea vectorâ€‘store, visualiza insights, exporta CSV/Excel.                                           |
| **main.py**                           | Punto de entrada por consola: ejecuta preâ€‘flight (SystemChecker), inicializa `IntegratedNewsSystem`, modo demo, batch o interactivo. |
| **verify.py**                         | Script independiente que solo corre `SystemChecker`.                                                                                 |
| **src/core/system.py**                | Clase *Ãºnica fuente de verdad* que orquesta procesador de datos, vectorâ€‘store, RAG y agentes.                                        |
| **src/agents/llama\_agents.py**       | Wrapper de agentes â€œbaseâ€ simples (text, analysis, conversational) sobre Llama.                                                      |
| **src/agents/specialized\_agents.py** | Registra y devuelve agentes temÃ¡ticos (temporal, comparativo, sÃ­ntesisâ€¦).                                                            |
| **src/agents/new\_agents\_graph.py**  | Implementa un flujo LangGraph que combina los agentes para anÃ¡lisis complejos.                                                       |
| **src/data/data\_processor.py**       | Limpia el Excel, normaliza fechas/columnas y genera `Document` para embeddings.                                                      |
| **src/data/vectorstore\_manager.py**  | Capa de persistencia: crea / abre ChromaDB, inserta documentos, reporta stats.                                                       |
| **models/**                           | Espacio para cÃ³digo relacionado con embeddings o pipelines ML adicionales.                                                           |
| **utils/system\_checker.py**          | Comprueba dependencias, estructura, Ollama, etc. Devuelve reporte GOOD/WARNING/ERROR.                                                |
| **chroma\_db/**                       | AlmacÃ©n de vectores en disco (se autoâ€‘crea; puedes borrarlo para reâ€‘indexar).                                                        |

---

## Variables de entorno

ColÃ³calas en `.env` o exporta en tu shellÂ (*defaults mostrados*):

```env
OLLAMA_BASE_URL=http://localhost:11434
LLAMA_MODEL=llama3:8b
CHROMA_PERSIST_DIRECTORY=./chroma_db
COLLECTION_NAME=news_collection
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
AGENT_CONFIG_ENV=development
```

## Comandos Ãºtiles

| Tarea                          | Comando                                  |
| ------------------------------ | ---------------------------------------- |
| Instalar deps (Pipenv)         | `pipenv install`                         |
| Exportar deps                  | `pipenv requirements > requirements.txt` |
| Crear vectorâ€‘store limpio      | Elimina `chroma_db/` y ejecuta app/CLI   |
| Actualizar estado en Streamlit | BotÃ³n ğŸ”„ â€œActualizar Estadoâ€             |
| Ejecutar tests                 | `pytest -q`                              |

## Notas de rendimiento y alcance del desarrollo

* El proyecto se desarrollÃ³ en un **periodo acotado**; es posible que encuentres oportunidades de refactor o mejora de UX.
* Para optimizar tiempos de respuesta:

  * MantÃ©n Ollama cargado con el modelo en memoria.
  * Ajusta `CHUNK_SIZE` y `CHUNK_OVERLAP` en `.env` segÃºn tus recursos.
  * Considera usar un modelo mÃ¡s pequeÃ±o si tu equipo es limitado.

---

